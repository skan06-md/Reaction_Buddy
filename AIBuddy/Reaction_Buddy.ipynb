{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0522a391-2537-48ff-9027-9ffaa0432938",
   "metadata": {},
   "source": [
    "## Importing the SpeechRecognition api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43044ddf-ead0-4bb7-bfcb-2b30ce51ef14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading speechrecognition-3.14.5-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.12.2)\n",
      "Downloading speechrecognition-3.14.5-py3-none-any.whl (32.9 MB)\n",
      "   ---------------------------------------- 0.0/32.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/32.9 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 0.2/32.9 MB 2.5 MB/s eta 0:00:14\n",
      "    --------------------------------------- 0.5/32.9 MB 3.8 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.1/32.9 MB 6.2 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.5/32.9 MB 7.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.0/32.9 MB 7.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.6/32.9 MB 8.4 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 3.3/32.9 MB 9.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.3/32.9 MB 10.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 5.4/32.9 MB 12.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 6.3/32.9 MB 13.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 7.8/32.9 MB 14.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 9.2/32.9 MB 16.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 10.8/32.9 MB 21.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 12.8/32.9 MB 28.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 15.1/32.9 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 17.7/32.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 20.6/32.9 MB 54.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 24.8/32.9 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 28.7/32.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.9 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.8/32.9 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.9/32.9 MB 54.4 MB/s eta 0:00:00\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.14.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd5fc95-402e-4c84-a4cb-ff8b8761becf",
   "metadata": {},
   "source": [
    "### Debugging the frequency of audio that should be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c7d65c0-e086-4539-8388-2ae225a8757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone(device_index=18, sample_rate=48000) as source:\n",
    "    audio = r.record(source, duration=5)\n",
    "\n",
    "with open(\"debug.wav\", \"wb\") as f:\n",
    "    f.write(audio.get_wav_data())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e0cd061-3abb-4a11-ab0d-cb45a6a6539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      " thinks you said it was absolutely magical she loved how she got to see new toys getting made she loved exploring new parts of the factory this was just the beginning of a long\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone(device_index=18) as source:\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)\n",
    "try:\n",
    "    print(\" thinks you said \" + r.recognize_google(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903317f-0f0c-4678-83e9-c8245fd47bbb",
   "metadata": {},
   "source": [
    "### Looping so it doesn't stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09b0210d-a609-4563-93e5-e42f2856a4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening continuously... Press ctrl to stop.\n",
      ">> Batman tomorrow\n",
      ">> to the Discovery Park let's talk about the tool where are we when it comes to\n",
      ">> play some people might think what you mean we're at Chachi bt5 but like from your perspective\n",
      ">> where do you think we are so I could I could I could\n",
      ">> he's talking about you know digital twins Earth observation models\n",
      ">> one of the things that have resonated with me is this concept\n",
      ">> alphago\n",
      ">> go Champion early on in the game and its 37th move\n",
      ">> right now it's at a place where it answers questions\n",
      ">> it takes an average of reality and then gives you\n",
      ">> move 37 was this view into how AI can be creative\n",
      "\n",
      "Stopping transcription.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import keyboard \n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone(device_index=18) as source:\n",
    "    print(\"Listening continuously... Press ctrl to stop.\")\n",
    "\n",
    "    while(True):\n",
    "        if keyboard.is_pressed('ctrl'):\n",
    "            print(\"\\nStopping transcription.\")\n",
    "            break\n",
    "\n",
    "        audio = r.record(source, duration=5)\n",
    "\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(\">>\", text)\n",
    "        except sr.UnknownValueError:\n",
    "            pass\n",
    "        except sr.RequestError as e:\n",
    "            print(\"API error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df17224-44f4-4961-8d92-ea82750fa408",
   "metadata": {},
   "source": [
    "#### Creating a context machine that constantly updates the context of whats happening in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91b2343-aa94-41bc-a440-8da011fb42c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.27.2)\n",
      "Requirement already satisfied: shellingham in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: typer>=0.23.1 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from typer-slim->transformers) (0.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.14.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (8.1.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (13.3.5)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shaik mohammed anas\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f089a-f6fe-4937-81ad-d28d9d5b4c36",
   "metadata": {},
   "source": [
    "### Download the model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039ca5da-a50f-4faf-9750-08c2f7a5ac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAIK MOHAMMED ANAS\\anaconda3\\envs\\context_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers working.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "print(\"Transformers working.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5119114b-9c96-40af-ac9a-a61c1a53a7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAIK MOHAMMED ANAS\\anaconda3\\envs\\context_env\\lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41836264-72bd-4fe2-8969-87614698bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 50, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text needs to be summarized . It contains multiple ideas about machine learning and context modeling.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"Falconsai/text_summarization\"\n",
    ")\n",
    "\n",
    "text = \"This is a long text that needs to be summarized. It contains multiple ideas about machine learning and context modeling.\"\n",
    "\n",
    "result = summarizer(text, max_length=50, min_length=10, do_sample=False)\n",
    "\n",
    "print(result[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11c90d56-2e7f-4b61-835c-88acab139d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading summarizer...\n",
      "Listening continuously... Press ctrl to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 120, but your input_length is only 14. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Chunk:\n",
      "and it teaches you lessons that you will not forget\n",
      "\n",
      "Updated Context:\n",
      "and it teaches you lessons that you will not forget . it is a lesson that you won't forget if you forget it . and it will teach you lessons .\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 120, but your input_length is only 71. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Chunk:\n",
      "to see Humanity in its most glorious moments War teaches you about sorrow\n",
      "\n",
      "Updated Context:\n",
      "Previous summary: and it teaches you lessons that you will not forget . it is a lesson that you won't forget if you forget it . and it will teach you lessons .\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 120, but your input_length is only 70. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Chunk:\n",
      "and then that fragility War teaches you about death\n",
      "\n",
      "Updated Context:\n",
      "Previous Summary: Previous summary: and it teaches you lessons that you will not forget . it is a lesson that you won't forget if you forget it . and it will teach you lessons .\n",
      "======================================================================\n",
      "\n",
      "Stopping transcription.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "import keyboard \n",
    "\n",
    "print(\"loading summarizer...\")\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"Falconsai/text_summarization\"\n",
    ")\n",
    "r = sr.Recognizer()\n",
    "context_summary=\"\"\n",
    "\n",
    "def update_context(old_summary, new_chunk):\n",
    "\n",
    "    if old_summary.strip() == \"\":\n",
    "        combined = new_chunk\n",
    "    else:\n",
    "        combined = f\"\"\"\n",
    "        Previous summary:\n",
    "        {old_summary}\n",
    "\n",
    "        New transcript:\n",
    "        {new_chunk}\n",
    "\n",
    "        Update the summary to reflect new information.\n",
    "        \"\"\"\n",
    "\n",
    "    result = summarizer(\n",
    "        combined,\n",
    "        max_length=120,\n",
    "        min_length=30,\n",
    "        do_sample=False\n",
    "    )[0][\"summary_text\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "with sr.Microphone(device_index=18) as source:\n",
    "    print(\"Listening continuously... Press ctrl to stop.\")\n",
    "\n",
    "    while(True):\n",
    "        if keyboard.is_pressed('ctrl'):\n",
    "            print(\"\\nStopping transcription.\")\n",
    "            break\n",
    "\n",
    "        audio = r.record(source, duration=10)\n",
    "\n",
    "        try:\n",
    "            audio = r.record(source, duration=10)\n",
    "            chunk = r.recognize_google(audio)\n",
    "            \n",
    "            print(\"\\nNew Chunk:\")\n",
    "            print(chunk)\n",
    "\n",
    "            context_summary = update_context(context_summary, chunk)\n",
    "\n",
    "            print(\"\\nUpdated Context:\")\n",
    "            print(context_summary)\n",
    "            print(\"=\" * 70)\n",
    "        except sr.UnknownValueError:\n",
    "            pass\n",
    "        except sr.RequestError as e:\n",
    "            print(\"API error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c977e0-fb2a-4d4e-836a-aafd5b3ee0d9",
   "metadata": {},
   "source": [
    "### Making emotions from the updated context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0445e3b1-d388-49ee-a6b7-930cff281cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'anger', 'score': 0.004384801723062992},\n",
       " {'label': 'disgust', 'score': 0.004861755762249231},\n",
       " {'label': 'fear', 'score': 0.003753639990463853},\n",
       " {'label': 'joy', 'score': 0.0015306900022551417},\n",
       " {'label': 'neutral', 'score': 0.029505236074328423},\n",
       " {'label': 'sadness', 'score': 0.9535338282585144},\n",
       " {'label': 'surprise', 'score': 0.0024300655350089073}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "result = emotion_classifier(\"I lost her but death has a meaning and he death will not go in va\")\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8d05f88-5eb2-497f-930f-f694dff1113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading summarizer...\n",
      "loading emotion model...\n",
      "Listening continuously... Press 's' to stop.\n",
      "\n",
      "New Chunk:\n",
      "is a daily set of meditations and exercises for you but you can also select your own if you've ever wanted to try meditating like I did headspace makes it easy\n",
      "detected emotion: neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 80, but your input_length is only 45. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Context:\n",
      "you can also select your own if you've ever wanted to try meditating like I did headspace .\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 80, but your input_length is only 57. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Chunk:\n",
      "all you have to do is sign up using the link in my description or scan the QR code currently on screen lost doesn't\n",
      "detected emotion: neutral\n",
      "\n",
      "Updated Context:\n",
      "you can also select your own if you've ever wanted to try meditating like I did headspace . all you have to do is sign up using the link in my description .\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 80, but your input_length is only 72. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Chunk:\n",
      "perhaps even billions of people in the world like this one this idea would be repeated by Albert Camus who famously made\n",
      "detected emotion: neutral\n",
      "\n",
      "Updated Context:\n",
      "you can also select your own if you've ever wanted to try meditating like I did headspace . all you have to do is sign up using the link in my description .\n",
      "======================================================================\n",
      "\n",
      "New Chunk:\n",
      "philosophy when we think of the desire to not exist we usually imagine something akin to this kind of thinking the idea that life is meaningless and insufferable is a popular one\n",
      "detected emotion: anger\n",
      "\n",
      "Updated Context:\n",
      "you can also select your own if you've ever wanted to try meditating like I did headspace . all you have to do is sign up using the link in my description .\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 80, but your input_length is only 71. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Chunk:\n",
      "but to experience non experience the desire is not a logical set of beliefs about the characteristics of life but the comp\n",
      "detected emotion: fear\n",
      "\n",
      "Updated Context:\n",
      "you can also select your own if you've ever wanted to try meditating like I did headspace .\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 80, but your input_length is only 63. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Chunk:\n",
      "this is entirely unbearable to not want to die but also wanting to simply not exist implies a contradictory hope that one might continue to go on\n",
      "detected emotion: sadness\n",
      "\n",
      "Updated Context:\n",
      "you can also select your own if you've ever wanted to try meditating like I did headspace . this is entirely unbearable to not want to die but also wanting to simply not exist implies a contradictory hope that one might continue to go on .\n",
      "======================================================================\n",
      "\n",
      "New Chunk:\n",
      "when a person has two contradictory beliefs but can only embody one of them they will pick the one that is easier to exhibit in this case it's easy to suggest that the people who\n",
      "detected emotion: neutral\n",
      "\n",
      "Updated Context:\n",
      "you can also select your own if you've ever wanted to try meditating like I did headspace . this is entirely unbearable to not want to die but also wanting to simply not exist implies a contradictory hope that one might continue to go on .\n",
      "======================================================================\n",
      "\n",
      "New Chunk:\n",
      "it takes a certain dedication to accept death of course there is something to be said for this idea after all most people would hesitate to see death as a solution to\n",
      "detected emotion: fear\n",
      "\n",
      "Updated Context:\n",
      "you can also select your own if you've ever wanted to try meditating like I did headspace . this is entirely unbearable to not want to die but also wanting to simply not exist implies a contradictory hope that one might continue to go on .\n",
      "======================================================================\n",
      "\n",
      "Stopping transcription.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "import keyboard\n",
    "\n",
    "print(\"loading summarizer...\")\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"Falconsai/text_summarization\"\n",
    ")\n",
    "\n",
    "print(\"loading emotion model...\")\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "r = sr.Recognizer()\n",
    "context_summary = \"\"\n",
    "\n",
    "def update_context(old_summary, new_chunk):\n",
    "    combined = (old_summary + \" \" + new_chunk).strip()\n",
    "\n",
    "    result = summarizer(\n",
    "        \"summarize: \" + combined,\n",
    "        max_length=80,\n",
    "        min_length=20,\n",
    "        truncation=True,   # added to remove warning\n",
    "        do_sample=False\n",
    "    )[0][\"summary_text\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "def detect_emotion(text):\n",
    "    scores = emotion_classifier(text)[0]\n",
    "    scores = sorted(scores, key=lambda x: x[\"score\"], reverse=True)\n",
    "    return scores[0][\"label\"]\n",
    "\n",
    "with sr.Microphone(device_index=18, sample_rate=48000) as source:\n",
    "    print(\"Listening continuously... Press 's' to stop.\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if keyboard.is_pressed('s'):\n",
    "            print(\"\\nStopping transcription.\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            audio = r.record(source, duration=10)\n",
    "            chunk = r.recognize_google(audio)\n",
    "\n",
    "            print(\"\\nNew Chunk:\")\n",
    "            print(chunk)\n",
    "\n",
    "            emotion_label = detect_emotion(chunk)\n",
    "            print(\"detected emotion:\", emotion_label)\n",
    "\n",
    "            context_summary = update_context(context_summary, chunk)\n",
    "\n",
    "            print(\"\\nUpdated Context:\")\n",
    "            print(context_summary)\n",
    "            print(\"=\" * 70)\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            pass\n",
    "        except sr.RequestError as e:\n",
    "            print(\"API error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c9a34-ea3b-4282-b330-738e06567e94",
   "metadata": {},
   "source": [
    "### making a reaction bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecaebb1b-d25a-4336-8ba4-346d87eb7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading summarizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAIK MOHAMMED ANAS\\anaconda3\\envs\\context_env\\lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading emotion model...\n",
      "loading reaction model...\n",
      "Listening continuously... Press 'ctrl' to stop.\n",
      "\n",
      "New Chunk:\n",
      "that these tapes all these tapes are pre-recorded and honestly that shouldn't be a surprise phone guys calls are recordings in every game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 80, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected emotion: surprise\n",
      "\n",
      "Updated Context:\n",
      "all these tapes are pre-recorded and honestly that shouldn't be a surprise phone guys calls are recordings in every game .\n",
      "\n",
      "AI Reaction:\n",
      "I'm sorry, but I don't have an emotional response to a video. Please provide more context or details to understand my emotion.\n",
      "======================================================================\n",
      "\n",
      "New Chunk:\n",
      "I meant for the night security guard from months ago need more proof night sixes call references a birthday party happening as the last event before the building\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 80, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected emotion: neutral\n",
      "\n",
      "Updated Context:\n",
      "all these tapes are pre-recorded and honestly that shouldn't be a surprise phone guys call are recordings in every game . I meant for the night security guard from months ago need more proof night sixes call references a birthday party .\n",
      "\n",
      "AI Reaction:\n",
      "Hey, I don't really see your point here. Pre-recorded tapes are definitely a thing in sports, and it's not a surprise that they can be used as\n",
      "======================================================================\n",
      "\n",
      "New Chunk:\n",
      "play Colton telling us that one of the new toy animatronics spit someone during the day why else would the new robots be scrapped will the old ones get kept for possible re\n",
      "detected emotion: neutral\n",
      "\n",
      "Updated Context:\n",
      "all these tapes are pre-recorded and honestly that shouldn't be a surprise phone guys call are recordings in every game . I meant for the night security guard from months ago need more proof night sixes call references a birthday party .\n",
      "\n",
      "AI Reaction:\n",
      "Emoticon: ðŸ˜Ž\n",
      "\n",
      "Response: Of course, your friend! I didn't realize the whole series of tapes was pre-recorded. I'm\n",
      "======================================================================\n",
      "\n",
      "New Chunk:\n",
      "that means he's not likely the one to get bit and instead the person who follows him on day shift is leaving Jeremy as the most likely frontal lobe candid\n",
      "detected emotion: neutral\n",
      "\n",
      "Updated Context:\n",
      "I meant for the night security guard from months ago need more proof night sixes call references a birthday party . he's not likely the one to get bit and instead the person who follows him on day shift is leaving Jeremy as the most likely frontal lobe candid .\n",
      "\n",
      "AI Reaction:\n",
      "Emotion: neutral\n",
      "\n",
      "Response: Okay, I see. Based on the information provided, it looks like the night security guard mentioned earlier has been seen at birthday parties in the past,\n",
      "======================================================================\n",
      "\n",
      "New Chunk:\n",
      "go past a grinning purple guy to see five dead bodies sorry no fireworks this time foxy and how do we know it's the FNAF one location well it's the only time the game\n",
      "detected emotion: surprise\n",
      "\n",
      "Updated Context:\n",
      "I meant for the night security guard from months ago need more proof night sixes call references a birthday party . go past a grinning purple guy to see five dead bodies sorry no fireworks this time foxy .\n",
      "\n",
      "AI Reaction:\n",
      "Aww, I'm so sorry to hear about the dead bodies! Based on the text, I imagine you were in a nightclub with friends, and someone called you to confirm that a\n",
      "======================================================================\n",
      "\n",
      "Stopping transcription.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "import keyboard\n",
    "\n",
    "print(\"loading summarizer...\")\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"Falconsai/text_summarization\"\n",
    ")\n",
    "\n",
    "print(\"loading emotion model...\")\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "print(\"loading reaction model...\")\n",
    "reaction_model = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    ")\n",
    "\n",
    "r = sr.Recognizer()\n",
    "context_summary = \"\"\n",
    "\n",
    "def update_context(old_summary, new_chunk):\n",
    "    combined = (old_summary + \" \" + new_chunk).strip()\n",
    "\n",
    "    result = summarizer(\n",
    "        \"summarize: \" + combined,\n",
    "        max_length=80,\n",
    "        min_length=20,\n",
    "        truncation=True,   # added to remove warning\n",
    "        do_sample=False\n",
    "    )[0][\"summary_text\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "def detect_emotion(text):\n",
    "    scores = emotion_classifier(text)[0]\n",
    "    scores = sorted(scores, key=lambda x: x[\"score\"], reverse=True)\n",
    "    return scores[0][\"label\"]\n",
    "\n",
    "def generate_reaction(context, emotion):\n",
    "\n",
    "    prompt = f\"\"\"<|system|>\n",
    "You are a casual human reacting to a video with your friend.\n",
    "Respond in ONE natural sentence with ONE emoji at the end.\n",
    "Do not repeat the summary.\n",
    "<|user|>\n",
    "Detected emotion: {emotion}\n",
    "\n",
    "Summary: {context}\n",
    "\n",
    "React.\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "    response = reaction_model(\n",
    "        prompt,\n",
    "        max_new_tokens=40,\n",
    "        do_sample=True,\n",
    "        temperature=0.8,\n",
    "        pad_token_id=reaction_model.tokenizer.eos_token_id\n",
    "    )[0][\"generated_text\"]\n",
    "\n",
    "    reply = response.split(\"<|assistant|>\")[-1].strip()\n",
    "    return reply\n",
    "\n",
    "with sr.Microphone(device_index=18, sample_rate=48000) as source:\n",
    "    print(\"Listening continuously... Press 'ctrl' to stop.\")\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if keyboard.is_pressed('ctrl'):\n",
    "            print(\"\\nStopping transcription.\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            audio = r.record(source, duration=10)\n",
    "            chunk = r.recognize_google(audio)\n",
    "\n",
    "            print(\"\\nNew Chunk:\")\n",
    "            print(chunk)\n",
    "\n",
    "            emotion_label = detect_emotion(chunk)\n",
    "            print(\"detected emotion:\", emotion_label)\n",
    "\n",
    "            context_summary = update_context(context_summary, chunk)\n",
    "\n",
    "            print(\"\\nUpdated Context:\")\n",
    "            print(context_summary)\n",
    "\n",
    "            reaction= generate_reaction(context_summary,emotion_label)\n",
    "            \n",
    "            print(\"\\nAI Reaction:\")\n",
    "            print(reaction)\n",
    "            print(\"=\" * 70)\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            pass\n",
    "        except sr.RequestError as e:\n",
    "            print(\"API error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b5378-c1c5-4179-b890-15b7b498ce47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b3751-934f-4194-bc1a-3063be5141cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context_env",
   "language": "python",
   "name": "context_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
